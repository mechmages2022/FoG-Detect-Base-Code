{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (5.18.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from plotly) (23.2)\n",
      "Requirement already satisfied: cufflinks in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from cufflinks) (1.26.3)\n",
      "Requirement already satisfied: pandas>=0.19.2 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from cufflinks) (2.2.0)\n",
      "Requirement already satisfied: plotly>=4.1.1 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from cufflinks) (5.18.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from cufflinks) (1.16.0)\n",
      "Requirement already satisfied: colorlover>=0.2.1 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from cufflinks) (0.3.0)\n",
      "Requirement already satisfied: setuptools>=34.4.1 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from cufflinks) (65.5.0)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from cufflinks) (8.20.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from cufflinks) (8.1.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (2.17.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (5.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (0.2.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from pandas>=0.19.2->cufflinks) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from pandas>=0.19.2->cufflinks) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from pandas>=0.19.2->cufflinks) (2023.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from plotly>=4.1.1->cufflinks) (8.2.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from plotly>=4.1.1->cufflinks) (23.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from jedi>=0.16->ipython>=5.3.0->cufflinks) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->cufflinks) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from stack-data->ipython>=5.3.0->cufflinks) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from stack-data->ipython>=5.3.0->cufflinks) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\araga\\.vscode\\machine_learning\\lib\\site-packages (from stack-data->ipython>=5.3.0->cufflinks) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly\n",
    "!pip install cufflinks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import plotly.express as px\n",
    "import cufflinks as cf\n",
    "from plotly.offline import download_plotlyjs,init_notebook_mode,iplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import Pool, CatBoostClassifier, cv\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_validate, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import average_precision_score,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all tdcsfog '.csv' train files\n",
    "tdcsfog_path= '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog'\n",
    "tdcsfog_list= []\n",
    "\n",
    "for file_name in os.listdir(tdcsfog_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path= os.path.join(tdcsfog_path,file_name)\n",
    "        df= pd.read_csv(file_path)\n",
    "        df['Time']= df['Time']/(len(df)-1) \n",
    "        tdcsfog_list.append(df)\n",
    "     \n",
    "tdcsfog = pd.concat(tdcsfog_list,axis= 0)\n",
    "tdcsfog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defog_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog'\n",
    "\n",
    "defog_list = []\n",
    "\n",
    "for file_name in os.listdir(defog_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(defog_path, file_name)\n",
    "        file = pd.read_csv(file_path)\n",
    "        file.Time = file.Time / (len(file) - 1)\n",
    "        defog_list.append(file)\n",
    "\n",
    "defog = pd.concat(defog_list, axis = 0)\n",
    "\n",
    "defog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing memory usage of dataset\n",
    "\n",
    "def reduce_memory_usage(df):\n",
    "    \n",
    "    init_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(init_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype.name\n",
    "        if ((col_type != 'datetime64[ns]') & (col_type != 'category')):\n",
    "            if (col_type != 'object'):\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "\n",
    "                else:\n",
    "#                     if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "#                         df[col] = df[col].astype(np.float16)\n",
    "                    if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                df[col] = df[col].astype('category')\n",
    "    mem_usg = df.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage became: \",mem_usg,\" MB\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defog= reduce_memory_usage(tdcsfog)\n",
    "defog= reduce_memory_usage(defog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defog= defog[(defog['Valid']==1) & (defog['Task']==1)]\n",
    "defog.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defog= defog.iloc[:,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged= pd.concat([tdcsfog,defog],axis=0)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_merged = merged.iloc[:,0:4]  \n",
    "X = tdcsfog.iloc[:,0:4]  \n",
    "y1 = merged['StartHesitation']  # target variable for StartHesitation\n",
    "y2 = merged['Turn']  # target variable for Turn\n",
    "y3 = tdcsfog['Walking']  # target variable for Walking\n",
    "X_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_ones= np.where(y1==1)[0] #indices of ones\n",
    "np.random.seed(10)\n",
    "n1_ones= (y1==1).sum() #total of ones\n",
    "y1_zeros= np.random.choice(np.where(y1==0)[0],size= n1_ones,replace= False) # chose same n1_ones from indices of zeros\n",
    "\n",
    "y1_balanced_idx= np.sort(np.concatenate([y1_zeros,y1_ones]))\n",
    "y1_balanced_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_balanced= X_merged.iloc[y1_balanced_idx,:]\n",
    "y1_balanced= y1.iloc[y1_balanced_idx]\n",
    "X1_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_ones= np.where(y2==1)[0]\n",
    "np.random.seed(10)\n",
    "\n",
    "n2_ones= (y2==1).sum()\n",
    "y2_zeros= np.random.choice(np.where(y2==0)[0],size= n2_ones,replace= False)\n",
    "\n",
    "y2_balanced_idx= np.sort(np.concatenate([y2_zeros,y2_ones]))\n",
    "\n",
    "X2_balanced= X_merged.iloc[y2_balanced_idx,:]\n",
    "y2_balanced= y2.iloc[y2_balanced_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3_ones= np.where(y3==1)[0]\n",
    "np.random.seed(10)\n",
    "\n",
    "n3_ones= (y3==1).sum()\n",
    "y3_zeros= np.random.choice(np.where(y3==0)[0],size= n3_ones,replace= False)\n",
    "\n",
    "y3_balanced_idx= np.sort(np.concatenate([y3_zeros,y3_ones]))\n",
    "\n",
    "X3_balanced= X.iloc[y3_balanced_idx,:]\n",
    "y3_balanced= y3.iloc[y3_balanced_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1_balanced, y1_balanced, test_size = 0.2, random_state = 42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_balanced, y2_balanced, test_size = 0.2, random_state = 42)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3_balanced, y3_balanced, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to minimize outliers: \n",
    "scaler1 = MinMaxScaler()\n",
    "X1_train = scaler1.fit_transform(X1_train)\n",
    "X1_test = scaler1.transform(X1_test)\n",
    "\n",
    "scaler2 = MinMaxScaler()\n",
    "X2_train = scaler2.fit_transform(X2_train)\n",
    "X2_test = scaler2.transform(X2_test)\n",
    "\n",
    "scaler3 = MinMaxScaler()\n",
    "X3_train = scaler3.fit_transform(X3_train)\n",
    "X3_test = scaler3.transform(X3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Assuming X2_train and X2_test have shapes (3624977, 4) and (906245, 4) respectively\n",
    "\n",
    "X2_train_reshaped = X2_train.reshape((X2_train.shape[0], X2_train.shape[1], 1))\n",
    "X2_test_reshaped = X2_test.reshape((X2_test.shape[0], X2_test.shape[1], 1))\n",
    "\n",
    "\n",
    "# Define the BNN model\n",
    "\n",
    "model_bnn = Sequential()\n",
    "model_bnn.add(Bidirectional(LSTM(64, activation='relu'), input_shape=(X2_train_reshaped.shape[1], X2_train_reshaped.shape[2])))\n",
    "model_bnn.add(Dropout(0.5))\n",
    "model_bnn.add(Dense(32, activation='relu'))\n",
    "model_bnn.add(Dense(1, activation='sigmoid'))  # Adjust this depending on your problem\n",
    "\n",
    "# Compile the model\n",
    "model_bnn.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])  # Adjust loss function as needed\n",
    "\n",
    "# Train the model\n",
    "model_bnn.fit(X2_train_reshaped, y2_train, epochs=10, batch_size=128, validation_split=0.2, callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "print(X2_train_reshaped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
